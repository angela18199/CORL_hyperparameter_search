{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 364
    },
    "executionInfo": {
     "elapsed": 969,
     "status": "ok",
     "timestamp": 1602186328543,
     "user": {
      "displayName": "Richard Watson",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg_aaSfAKowaEMKH5EBs_BIRHzGivNQen-5Osb-=s64",
      "userId": "11605160484643735164"
     },
     "user_tz": 240
    },
    "id": "qHWBoJA3KA53",
    "outputId": "55506d60-0943-42aa-9773-4125172f892e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Oct  8 19:45:27 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 455.23.05    Driver Version: 418.67       CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   36C    P0    25W / 300W |      0MiB / 16130MiB |      0%      Default |\n",
      "|                               |                      |                 ERR! |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# This ensures that a gpu is being used by the current google colab session.\n",
    "\n",
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
    "  print('and then re-execute this cell.')\n",
    "else:\n",
    "  print(gpu_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zLd2Yfk653Gu"
   },
   "outputs": [],
   "source": [
    "# This code block is used to access your google drive\n",
    "\n",
    "from google.colab import drive\n",
    "ROOT = \"/content/drive\"\n",
    "drive.mount(ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CwHxwKkL6qh3"
   },
   "outputs": [],
   "source": [
    "# Make sure this points to the project folder\n",
    "\n",
    "%cd drive/'My Drive'/CORL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZQXpBJPg0-V1"
   },
   "outputs": [],
   "source": [
    "%cd attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/yu/Documents/Duke/courses/capstone/RL_for_vehicle/paper:repository/CORL/attention\n"
     ]
    }
   ],
   "source": [
    "%cd /Users/yu/Documents/Duke/courses/capstone/RL_for_vehicle/paper:repository/CORL/attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "6pplMLCu-M8m"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorboard_logger in /anaconda3/lib/python3.7/site-packages (0.1.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /anaconda3/lib/python3.7/site-packages (from tensorboard_logger) (1.4.1)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /anaconda3/lib/python3.7/site-packages (from tensorboard_logger) (5.4.1)\n",
      "Requirement already satisfied: numpy in /anaconda3/lib/python3.7/site-packages (from tensorboard_logger) (1.16.2)\n",
      "Requirement already satisfied: six in /anaconda3/lib/python3.7/site-packages (from tensorboard_logger) (1.12.0)\n",
      "Requirement already satisfied: protobuf in /anaconda3/lib/python3.7/site-packages (from tensorboard_logger) (3.11.3)\n",
      "Requirement already satisfied: setuptools in /anaconda3/lib/python3.7/site-packages (from protobuf->tensorboard_logger) (41.4.0)\n"
     ]
    }
   ],
   "source": [
    "# install dependencies\n",
    "!pip install tensorboard_logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "3cgIK0U5M26a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opts: Namespace(baseline='rollout', batch_size=64, bl_alpha=0.05, bl_warmup_epochs=1, checkpoint_encoder=False, checkpoint_epochs=1, data_distribution=None, embedding_dim=128, epoch_size=12800, epoch_start=0, eval_batch_size=1024, eval_only=False, exp_beta=0.8, graph_size=100, hidden_dim=128, load_path=None, log_dir='logs', log_step=50, lr_critic=0.0001, lr_decay=1.0, lr_model=0.0001, max_grad_norm=1.0, model='attention', n_encode_layers=3, n_epochs=100, no_cuda=False, no_progress_bar=False, no_tensorboard=False, normalization='batch', output_dir='outputs', problem='cvrp', resume=None, run_name='vrp100_rollout_20201113T172007', save_dir='outputs/cvrp_100/vrp100_rollout_20201113T172007', save_hrs=[1], seed=1234, shrink_size=None, tanh_clipping=10.0, use_cuda=False, val_dataset=None, val_size=10000)\n",
      "{'baseline': 'rollout',\n",
      " 'batch_size': 64,\n",
      " 'bl_alpha': 0.05,\n",
      " 'bl_warmup_epochs': 1,\n",
      " 'checkpoint_encoder': False,\n",
      " 'checkpoint_epochs': 1,\n",
      " 'data_distribution': None,\n",
      " 'embedding_dim': 128,\n",
      " 'epoch_size': 12800,\n",
      " 'epoch_start': 0,\n",
      " 'eval_batch_size': 1024,\n",
      " 'eval_only': False,\n",
      " 'exp_beta': 0.8,\n",
      " 'graph_size': 100,\n",
      " 'hidden_dim': 128,\n",
      " 'load_path': None,\n",
      " 'log_dir': 'logs',\n",
      " 'log_step': 50,\n",
      " 'lr_critic': 0.0001,\n",
      " 'lr_decay': 1.0,\n",
      " 'lr_model': 0.0001,\n",
      " 'max_grad_norm': 1.0,\n",
      " 'model': 'attention',\n",
      " 'n_encode_layers': 3,\n",
      " 'n_epochs': 100,\n",
      " 'no_cuda': False,\n",
      " 'no_progress_bar': False,\n",
      " 'no_tensorboard': False,\n",
      " 'normalization': 'batch',\n",
      " 'output_dir': 'outputs',\n",
      " 'problem': 'cvrp',\n",
      " 'resume': None,\n",
      " 'run_name': 'vrp100_rollout_20201113T172007',\n",
      " 'save_dir': 'outputs/cvrp_100/vrp100_rollout_20201113T172007',\n",
      " 'save_hrs': [1],\n",
      " 'seed': 1234,\n",
      " 'shrink_size': None,\n",
      " 'tanh_clipping': 10.0,\n",
      " 'use_cuda': False,\n",
      " 'val_dataset': None,\n",
      " 'val_size': 10000}\n",
      "Evaluating baseline model on evaluation dataset\n",
      "  0%|                                                    | 0/10 [00:00<?, ?it/s]^C\n",
      "Traceback (most recent call last):\n",
      "  File \"run.py\", line 199, in <module>\n",
      "    run(get_options())\n",
      "  File \"run.py\", line 112, in run\n",
      "    baseline = RolloutBaseline(model, problem, opts)\n",
      "  File \"/Users/yu/Documents/Duke/courses/capstone/RL_for_vehicle/paper:repository/CORL/attention/reinforce_baselines.py\", line 151, in __init__\n",
      "    self._update_model(model, epoch)\n",
      "  File \"/Users/yu/Documents/Duke/courses/capstone/RL_for_vehicle/paper:repository/CORL/attention/reinforce_baselines.py\", line 171, in _update_model\n",
      "    self.bl_vals = rollout(self.model, self.dataset, self.opts).cpu().numpy()\n",
      "  File \"/Users/yu/Documents/Duke/courses/capstone/RL_for_vehicle/paper:repository/CORL/attention/train.py\", line 43, in rollout\n",
      "    in tqdm(DataLoader(dataset, batch_size=opts.eval_batch_size), disable=opts.no_progress_bar)\n",
      "  File \"/Users/yu/Documents/Duke/courses/capstone/RL_for_vehicle/paper:repository/CORL/attention/train.py\", line 42, in <listcomp>\n",
      "    for bat\n",
      "  File \"/Users/yu/Documents/Duke/courses/capstone/RL_for_vehicle/paper:repository/CORL/attention/train.py\", line 37, in eval_model_bat\n",
      "    cost, _ = model(move_to(bat, opts.device))\n",
      "  File \"/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 547, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/Users/yu/Documents/Duke/courses/capstone/RL_for_vehicle/paper:repository/CORL/attention/nets/attention_model.py\", line 136, in forward\n",
      "    embeddings, _ = self.embedder(self._init_embed(input))\n",
      "  File \"/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 547, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/Users/yu/Documents/Duke/courses/capstone/RL_for_vehicle/paper:repository/CORL/attention/nets/graph_encoder.py\", line 203, in forward\n",
      "    h = self.layers(h)\n",
      "  File \"/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 547, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/anaconda3/lib/python3.7/site-packages/torch/nn/modules/container.py\", line 92, in forward\n",
      "    input = module(input)\n",
      "  File \"/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 547, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/anaconda3/lib/python3.7/site-packages/torch/nn/modules/container.py\", line 92, in forward\n",
      "    input = module(input)\n",
      "  File \"/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 547, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/Users/yu/Documents/Duke/courses/capstone/RL_for_vehicle/paper:repository/CORL/attention/nets/graph_encoder.py\", line 14, in forward\n",
      "    return input + self.module(input)\n",
      "  File \"/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 547, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/Users/yu/Documents/Duke/courses/capstone/RL_for_vehicle/paper:repository/CORL/attention/nets/graph_encoder.py\", line 97, in forward\n",
      "    attn = torch.softmax(compatibility, dim=-1)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "# This block will run the originial attention code with the below settings\n",
    "# The save_hrs are the checkpoint hours to save the model\n",
    "\n",
    "!python run.py --graph_size 100 --batch_size 64 --problem cvrp --baseline rollout --run_name 'vrp100_rollout' --save_hrs 1 --epoch_size 12800\n",
    "\n",
    "# this is an example of how to run evolution code\n",
    "#!python vrp_evolve.py --save_dir ../models/att_evo --save_hrs 1 --sigma 0.001 --lr 0.000001 --dataset_size 12800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Attention.ipynb",
   "provenance": [
    {
     "file_id": "11ZCL_l3YnTUHGbA1FBMEbavyu7LUrqgX",
     "timestamp": 1597335908999
    },
    {
     "file_id": "1-virH5eoLhntdlzQejTsUsO0undnzkrR",
     "timestamp": 1594813661497
    },
    {
     "file_id": "1k6NgvMVYkz07WDXLcS84XulCHmCdV2je",
     "timestamp": 1594515484374
    },
    {
     "file_id": "1GkySQlBY9x2Qft9q5ENyLrZerizdfiRq",
     "timestamp": 1593300375713
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
